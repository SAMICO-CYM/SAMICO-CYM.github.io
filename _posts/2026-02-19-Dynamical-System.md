---
title: Dynamical System
date: 2026-02-19 15:00:00 +0900
categories:
  - Mathematics
  - Dynamics
tags: []
math: true
---
## Definition 1
A dynamical system consists of a set of possible states, together with a rule that determines the present state in terms of past states. We will require that the rule be deterministic, which means that we can determine the present state (population, for example) uniquely from the past states. We will emphasize two types of dynamical systems. If the rule is applied at discrete times, it is called a discrete-time dynamical system, or also called maps. The other important type of dynamical system is essentially the limit of discrete systems with smaller and smaller updating times. The governing rule in that case becomes a set of differential equations, and the term continuous-time dynamical system is sometimes used.

---
## Definition 2
A function whose domain (input) space and range (output) space are the same will be called a  ***map*** . Let $x$ be a point and let $f$ be a map. ***The orbit of $x$ under $f$*** is the set of points $\{x, f(x), f^2(x), ... \}$. The starting point $x$ for the orbit is called the initial value of the orbit. A point $p$ is a fixed point of the map $f$ if $f(p)=p$.

---



이상적분은 다음과 같이 정의된다. The improper integarl is defined.